{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "068279d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 chart images and 26 non-chart images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "train_chart_folder = \"train/cropped\"\n",
    "train_nonchart_folder = \"train/nonchart\"\n",
    "\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)) \n",
    "])\n",
    "\n",
    "def load_images_as_tensors(folder):\n",
    "    tensors = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            tensor = to_tensor(img)\n",
    "            tensors.append(tensor)\n",
    "    return tensors\n",
    "\n",
    "chart_tensors = load_images_as_tensors(train_chart_folder)\n",
    "nonchart_tensors = load_images_as_tensors(train_nonchart_folder)\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(chart_tensors)} chart images and {len(nonchart_tensors)} non-chart images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10549f",
   "metadata": {},
   "source": [
    "used panda for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16960c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tensor = to_tensor(img)\n",
    "    return img, tensor\n",
    "\n",
    "input_image, input_tensor = preprocess_input_image(\"page.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3325ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Cosine with chart images: 0.9957340359687805\n",
      "Max Cosine with non-chart images: 0.9954390525817871\n",
      "Max SSIM with chart images: 0.62808555\n",
      "Max SSIM with non-chart images: 0.5917752\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "def compute_similarity(input_tensor, train_tensors):\n",
    "    cos_sims = []\n",
    "    ssim_scores = []\n",
    "    input_np = input_tensor.permute(1,2,0).numpy()\n",
    "    \n",
    "    for t in train_tensors:\n",
    "        cos_sim = cosine_similarity(\n",
    "            input_tensor.flatten().unsqueeze(0),\n",
    "            t.flatten().unsqueeze(0)\n",
    "        ).item()\n",
    "        cos_sims.append(cos_sim)\n",
    "        \n",
    "        # SSIM\n",
    "        t_np = t.permute(1,2,0).numpy()\n",
    "        if t_np.shape != input_np.shape:\n",
    "            t_np_resized = resize(t_np, input_np.shape, preserve_range=True, anti_aliasing=True)\n",
    "        else:\n",
    "            t_np_resized = t_np\n",
    "        ssim_score, _ = ssim(t_np_resized, input_np, channel_axis=2, full=True, data_range=1.0)\n",
    "        ssim_scores.append(ssim_score)\n",
    "    \n",
    "    return cos_sims, ssim_scores \n",
    "\n",
    "cos_chart, ssim_chart = compute_similarity(input_tensor, chart_tensors)\n",
    "cos_nonchart, ssim_nonchart = compute_similarity(input_tensor, nonchart_tensors)\n",
    "\n",
    "print(\"Max Cosine with chart images:\", max(cos_chart))\n",
    "print(\"Max Cosine with non-chart images:\", max(cos_nonchart))\n",
    "print(\"Max SSIM with chart images:\", max(ssim_chart))\n",
    "print(\"Max SSIM with non-chart images:\", max(ssim_nonchart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36aad27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image is likely a chart\n"
     ]
    }
   ],
   "source": [
    "if max(cos_chart) > max(cos_nonchart):\n",
    "    print(\"Input image is likely a chart\")\n",
    "else:\n",
    "    print(\"Input image is likely non-chart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e903ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image is likely a chart\n"
     ]
    }
   ],
   "source": [
    "if max(ssim_chart) > max(ssim_nonchart):\n",
    "    print(\"Input image is likely a chart\")\n",
    "else:\n",
    "    print(\"Input image is likely non-chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b01e4024",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cropped_region\n\u001b[32m     22\u001b[39m best_chart_img = chart_tensors[\u001b[32m0\u001b[39m].permute(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m).numpy()  \n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m cropped_region = find_matched_region(\u001b[43minput_img\u001b[49m, best_chart_img)\n\u001b[32m     27\u001b[39m resized_cropped_region = cv2.resize(cropped_region, (\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# cv2.imwrite(\"cropped_resized_image.png\", resized_cropped_region)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'input_img' is not defined"
     ]
    }
   ],
   "source": [
    "def find_matched_region(input_img, chart_img):\n",
    "    input_gray = cv2.cvtColor(input_img, cv2.COLOR_RGB2GRAY)\n",
    "    chart_gray = cv2.cvtColor(chart_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    result = cv2.matchTemplate(input_gray, chart_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    \n",
    "\n",
    "    chart_h, chart_w = chart_img.shape[:2]\n",
    "    \n",
    "\n",
    "    bottom_right = (max_loc[0] + chart_w, max_loc[1] + chart_h)\n",
    "    \n",
    "\n",
    "    cropped_region = input_img[max_loc[1]:bottom_right[1], max_loc[0]:bottom_right[0]]\n",
    "    \n",
    "    return cropped_region\n",
    "\n",
    "\n",
    "best_chart_img = chart_tensors[0].permute(1, 2, 0).numpy()  \n",
    "\n",
    "\n",
    "cropped_region = find_matched_region(input_img, best_chart_img)\n",
    "\n",
    "resized_cropped_region = cv2.resize(cropped_region, (224, 224))\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"cropped_resized_image.png\", resized_cropped_region)\n",
    "cv2.imshow(\"Cropped and Resized Image\", resized_cropped_region)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Cropped and resized image saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
