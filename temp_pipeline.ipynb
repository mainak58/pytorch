{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950d6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched cropped_11.png with score: 0.7248\n",
      "‚úÖ Matched cropped_13.png with score: 0.6419\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚ö†Ô∏è Skipping oversized template: Chart size (470, 3400, 3) > Input size (1700, 2800, 3)\n",
      "‚úÖ Matched cropped_5.png with score: 0.0611\n",
      "‚úÖ Matched cropped_7.png with score: 0.5969\n",
      "‚úÖ Matched cropped_9.png with score: 0.9738\n",
      "‚úÖ Matched cropped_test_10.png with score: 0.3362\n",
      "‚úÖ Matched cropped_test_12.png with score: 0.3604\n",
      "‚úÖ Matched cropped_test_14.png with score: 0.3519\n",
      "‚úÖ Matched cropped_test_16.png with score: 0.3248\n",
      "‚úÖ Matched cropped_test_18.png with score: 0.3374\n",
      "‚úÖ Matched cropped_test_2.png with score: 0.3539\n",
      "‚úÖ Matched cropped_test_20.png with score: 0.3078\n",
      "‚úÖ Matched cropped_test_22.png with score: 0.3170\n",
      "‚úÖ Matched cropped_test_4.png with score: 0.3474\n",
      "‚úÖ Matched cropped_test_6.png with score: 0.3390\n",
      "‚úÖ Matched cropped_test_8.png with score: 0.3503\n",
      "\n",
      "üéØ Best match: cropped_9.png with score: 0.9738\n",
      "üíæ Cropped region saved to best_matched_crop.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "page_img_path = \"page.png\"\n",
    "train_chart_folder = \"train/cropped\"\n",
    "output_path = \"best_matched_crop.png\"\n",
    "\n",
    "\n",
    "def load_image_paths(folder):\n",
    "    image_paths = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_paths.append(os.path.join(folder, filename))\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def find_matched_region(input_img, chart_img):\n",
    "    ih, iw = input_img.shape[:2]\n",
    "    ch, cw = chart_img.shape[:2]\n",
    "\n",
    "    if ch > ih or cw > iw:\n",
    "        print(f\"‚ö†Ô∏è Skipping oversized template: Chart size {chart_img.shape} > Input size {input_img.shape}\")\n",
    "        return None, -1\n",
    "\n",
    "\n",
    "    input_gray = cv2.cvtColor(input_img, cv2.COLOR_RGB2GRAY)\n",
    "    chart_gray = cv2.cvtColor(chart_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    result = cv2.matchTemplate(input_gray, chart_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    h, w = chart_img.shape[:2]\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    matched_region = input_img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "\n",
    "    return matched_region, max_val\n",
    "\n",
    "\n",
    "input_img = cv2.imread(page_img_path)\n",
    "if input_img is None:\n",
    "    raise FileNotFoundError(f\"Page image not found: {page_img_path}\")\n",
    "input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "chart_image_paths = load_image_paths(train_chart_folder)\n",
    "\n",
    "\n",
    "best_score = -1\n",
    "best_crop = None\n",
    "best_match_path = None\n",
    "\n",
    "for path in chart_image_paths:\n",
    "    chart_img = cv2.imread(path)\n",
    "    if chart_img is None:\n",
    "        print(f\"‚ö†Ô∏è Could not load image: {path}\")\n",
    "        continue\n",
    "\n",
    "    chart_img = cv2.cvtColor(chart_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cropped_region, score = find_matched_region(input_img, chart_img)\n",
    "    if score == -1:\n",
    "        continue  \n",
    "\n",
    "    print(f\"‚úÖ Matched {os.path.basename(path)} with score: {score:.4f}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_crop = cropped_region\n",
    "        best_match_path = path\n",
    "\n",
    "\n",
    "cropped = cv2.cvtColor(best_crop, cv2.COLOR_RGB2BGR)\n",
    "if best_crop is not None:\n",
    "    print(f\"\\nüéØ Best match: {os.path.basename(best_match_path)} with score: {best_score:.4f}\")\n",
    "\n",
    "    cropped_bgr = cv2.cvtColor(best_crop, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "    cv2.namedWindow(\"Best Matched Region\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Best Matched Region\", cropped_bgr)\n",
    "\n",
    "\n",
    "    h, w = cropped_bgr.shape[:2]\n",
    "    cv2.resizeWindow(\"Best Matched Region\", w, h)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save image if needed\n",
    "    cv2.imwrite(output_path, cropped_bgr)\n",
    "    print(f\"üíæ Cropped region saved to {output_path}\")\n",
    "else:\n",
    "    print(\"‚ùå No suitable match found.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
